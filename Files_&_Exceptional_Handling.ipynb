{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#1. Discuss the scenarios where multithreading is preferable to multiprocessing and scenarios where\n",
        "multiprocessing is a better choice."
      ],
      "metadata": {
        "id": "MrourZjhcMV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When deciding between multithreading and multiprocessing, it's essential to consider the nature of the task, the resources available, and the environment in which the application will run. Here are some scenarios where each approach is preferable:\n",
        "\n",
        "### Scenarios Favoring Multithreading\n",
        "\n",
        "1. **I/O-Bound Tasks**:\n",
        "   - Applications that spend a significant amount of time waiting for I/O operations (like network requests, file reading/writing, or database queries) benefit from multithreading. Threads can handle multiple I/O operations concurrently without needing multiple processes.\n",
        "\n",
        "2. **Shared Memory Access**:\n",
        "   - When tasks require frequent communication or sharing of data, multithreading can be more efficient since threads within the same process share memory space, making data exchange easier and faster.\n",
        "\n",
        "3. **Lightweight Context Switching**:\n",
        "   - Threads are generally lighter than processes, meaning that context switching between threads is faster. This can lead to performance improvements in applications that require high-frequency context switching.\n",
        "\n",
        "4. **Resource Limitations**:\n",
        "   - In environments with limited resources (like low-memory devices), using threads can be more efficient than spawning multiple processes, which require more memory overhead.\n",
        "\n",
        "5. **User Interface Applications**:\n",
        "   - In applications with a graphical user interface (GUI), multithreading is often used to keep the interface responsive while performing background tasks.\n",
        "\n",
        "### Scenarios Favoring Multiprocessing\n",
        "\n",
        "1. **CPU-Bound Tasks**:\n",
        "   - For tasks that require heavy CPU computations, multiprocessing is usually better. This approach can fully utilize multiple CPU cores, as each process runs independently in its own memory space, avoiding the Global Interpreter Lock (GIL) that can limit Python threads.\n",
        "\n",
        "2. **Isolation of Tasks**:\n",
        "   - When tasks need to be isolated (for instance, if one task crashes, it shouldn't affect others), multiprocessing is preferable. Each process runs independently, so errors in one do not propagate to others.\n",
        "\n",
        "3. **Heavy Memory Usage**:\n",
        "   - If tasks require substantial memory and can't share data efficiently, multiprocessing can help, as each process has its own memory space. This avoids memory bloat from shared data structures.\n",
        "\n",
        "4. **Scalability**:\n",
        "   - Multiprocessing can often scale better on multi-core systems, as it allows each process to run on a separate core, thus maximizing CPU utilization.\n",
        "\n",
        "5. **Long-Running Tasks**:\n",
        "   - For tasks that need to run for a long time, using separate processes can help manage resources better and avoid issues related to memory leaks or fragmentation in a single-threaded environment.\n",
        "\n",
        "### Conclusion\n",
        "\n",
        "In summary, choose multithreading for I/O-bound tasks and when you need lightweight, fast context switching with shared memory. Opt for multiprocessing for CPU-bound tasks requiring isolation, heavy memory use, and better scalability. The choice ultimately depends on the specific requirements and constraints of your application."
      ],
      "metadata": {
        "id": "M8x5t3k1X99d"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "McTKA-2FYc5l"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xh0aQ4lfYe6w"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2. Describe what a process pool is and how it helps in managing multiple processes efficiently."
      ],
      "metadata": {
        "id": "TnNOHpziYdaq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A **process pool** is a collection of pre-instantiated processes that are managed to handle multiple tasks concurrently without the overhead of creating and destroying processes repeatedly. It is particularly useful in scenarios where the overhead of process creation is high or when you want to efficiently manage a limited number of resources (like CPU cores).\n",
        "\n",
        "### Key Features of a Process Pool\n",
        "\n",
        "1. **Resource Management**:\n",
        "   - A process pool limits the number of concurrent processes to a predefined maximum. This prevents the system from being overwhelmed by too many processes, which can lead to performance degradation.\n",
        "\n",
        "2. **Reusability**:\n",
        "   - Once a process in the pool finishes its task, it can be reused for new tasks. This reduces the overhead associated with process creation and termination, making task execution more efficient.\n",
        "\n",
        "3. **Task Queueing**:\n",
        "   - When tasks are submitted to a process pool, they are typically placed in a queue. The pool then distributes these tasks to available processes as they become free, ensuring a steady flow of work.\n",
        "\n",
        "4. **Load Balancing**:\n",
        "   - The process pool can help balance the workload across the available processes, ensuring that no single process is overwhelmed while others remain idle.\n",
        "\n",
        "5. **Simplified Management**:\n",
        "   - Managing multiple processes can be complex, especially regarding synchronization and communication. A process pool abstracts much of this complexity, allowing developers to focus on task logic rather than process management.\n",
        "\n",
        "### Benefits of Using a Process Pool\n",
        "\n",
        "1. **Improved Performance**:\n",
        "   - By reusing processes and minimizing the overhead of process creation, a process pool can significantly improve the performance of applications that require parallel execution.\n",
        "\n",
        "2. **Scalability**:\n",
        "   - Process pools make it easier to scale applications by allowing them to adapt to varying workloads while efficiently managing system resources.\n",
        "\n",
        "3. **Error Handling**:\n",
        "   - Many process pool implementations provide built-in error handling, making it easier to manage failures in individual processes without affecting the entire system.\n",
        "\n",
        "4. **Flexibility**:\n",
        "   - Developers can configure the size of the pool based on the application's requirements and the available system resources, allowing for tailored performance tuning.\n",
        "\n",
        "### Common Implementations\n",
        "\n",
        "In Python, for example, the `concurrent.futures` module provides a `ProcessPoolExecutor`, which simplifies the creation and management of a process pool. Similarly, the `multiprocessing` module has a `Pool` class that enables the creation of a process pool with convenient methods for submitting tasks.\n",
        "\n",
        "### Conclusion\n",
        "\n",
        "A process pool is an effective strategy for managing multiple processes, enhancing performance, and improving resource utilization. By reusing processes and controlling concurrency, it provides a robust framework for handling parallel tasks in an efficient manner."
      ],
      "metadata": {
        "id": "t-z9ZNjSYtul"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hDYYhVEqY--k"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mt4aiTgWY_p7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3. Explain what multiprocessing is and why it is used in Python programs."
      ],
      "metadata": {
        "id": "AKQnNQWuY_bd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Multiprocessing** refers to the ability of a program to execute multiple processes concurrently. In the context of Python, it allows developers to take advantage of multiple CPU cores to run tasks in parallel, which can lead to significant performance improvements, especially for CPU-bound operations.\n",
        "\n",
        "### Key Concepts of Multiprocessing\n",
        "\n",
        "1. **Processes**:\n",
        "   - Each process has its own memory space, code, and data, which means that they operate independently of each other. This isolation helps prevent issues related to shared state and concurrency.\n",
        "\n",
        "2. **Inter-Process Communication (IPC)**:\n",
        "   - Since processes do not share memory, they communicate via IPC mechanisms like pipes, queues, and shared memory. This allows for data exchange between processes.\n",
        "\n",
        "3. **Global Interpreter Lock (GIL)**:\n",
        "   - In CPython (the standard Python implementation), the GIL prevents multiple threads from executing Python bytecode simultaneously. This means that multithreading is not effective for CPU-bound tasks. Multiprocessing, however, bypasses the GIL because each process runs in its own Python interpreter, allowing true parallelism.\n",
        "\n",
        "### Why Use Multiprocessing in Python?\n",
        "\n",
        "1. **Performance Improvement**:\n",
        "   - For CPU-bound tasks, such as mathematical computations or data processing, multiprocessing allows for parallel execution, utilizing multiple CPU cores. This can drastically reduce execution time compared to single-threaded approaches.\n",
        "\n",
        "2. **Task Isolation**:\n",
        "   - Each process runs independently. If one process crashes, it does not affect others, leading to increased robustness and easier error management.\n",
        "\n",
        "3. **Better Resource Utilization**:\n",
        "   - Multiprocessing can fully leverage the capabilities of modern multi-core processors, leading to more efficient use of available hardware.\n",
        "\n",
        "4. **Simplified Code for Certain Problems**:\n",
        "   - Some problems are naturally parallel (like processing a large dataset). Using multiprocessing can simplify the implementation of such solutions by breaking tasks into independent sub-tasks that can run concurrently.\n",
        "\n",
        "5. **Scalability**:\n",
        "   - Applications designed with multiprocessing can easily scale to utilize more CPU resources as they become available, making it easier to adapt to changing workloads.\n",
        "\n",
        "### Common Use Cases\n",
        "\n",
        "- **Data Processing**: Handling large datasets in parallel, such as in data analysis or machine learning tasks.\n",
        "- **Web Scraping**: Concurrently fetching data from multiple URLs to speed up data collection.\n",
        "- **Image Processing**: Applying transformations or filters to images in parallel.\n",
        "- **Scientific Computations**: Performing heavy mathematical calculations that can be divided into independent tasks.\n",
        "\n",
        "### Conclusion\n",
        "\n",
        "Multiprocessing is a powerful feature in Python that allows for concurrent execution of processes, making it an essential tool for improving performance in CPU-bound applications. By utilizing multiple cores and providing a clean separation of processes, it enhances both the efficiency and reliability of Python programs."
      ],
      "metadata": {
        "id": "vlDct9lRZSQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5SeQRuBWZYdH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yvfd0CyzZZe0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#4. Write a Python program using multithreading where one thread adds numbers to a list, and another\n",
        "thread removes numbers from the list. Implement a mechanism to avoid race conditions using\n",
        "threading.Lock."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "gidCHf8AZY-f",
        "outputId": "d16ab93b-3249-4978-da66-5fc63c998037"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-5-56309db7b258>, line 2)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-56309db7b258>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    thread removes numbers from the list. Implement a mechanism to avoid race conditions using\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's a Python program that demonstrates multithreading using threading.Lock to manage access to a shared list. One thread adds numbers to the list, while another removes them. The Lock ensures that only one thread can access the list at a time, preventing race conditions"
      ],
      "metadata": {
        "id": "W2N347z5Znj-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import time\n",
        "import random\n",
        "\n",
        "# Shared list\n",
        "shared_list = []\n",
        "lock = threading.Lock()\n",
        "\n",
        "# Function to add numbers to the list\n",
        "def add_numbers():\n",
        "    for i in range(10):\n",
        "        time.sleep(random.uniform(0.1, 0.5))  # Simulate some processing time\n",
        "        with lock:  # Acquire the lock before modifying the shared list\n",
        "            shared_list.append(i)\n",
        "            print(f\"Added: {i}, List: {shared_list}\")\n",
        "\n",
        "# Function to remove numbers from the list\n",
        "def remove_numbers():\n",
        "    for _ in range(10):\n",
        "        time.sleep(random.uniform(0.1, 0.5))  # Simulate some processing time\n",
        "        with lock:  # Acquire the lock before modifying the shared list\n",
        "            if shared_list:\n",
        "                removed = shared_list.pop(0)\n",
        "                print(f\"Removed: {removed}, List: {shared_list}\")\n",
        "            else:\n",
        "                print(\"List is empty, nothing to remove.\")\n",
        "\n",
        "# Create threads\n",
        "adder_thread = threading.Thread(target=add_numbers)\n",
        "remover_thread = threading.Thread(target=remove_numbers)\n",
        "\n",
        "# Start threads\n",
        "adder_thread.start()\n",
        "remover_thread.start()\n",
        "\n",
        "# Wait for both threads to complete\n",
        "adder_thread.join()\n",
        "remover_thread.join()\n",
        "\n",
        "print(\"Final List:\", shared_list)\n"
      ],
      "metadata": {
        "id": "Z8EymEvlZqhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "21f32SBZZsty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation:\n",
        "Shared List: The shared_list variable is where numbers are added or removed.\n",
        "\n",
        "Lock: A Lock object is created to manage access to the shared list.\n",
        "\n",
        "Adding Function: The add_numbers function simulates adding numbers to the list. It sleeps for a random duration to mimic processing time, then acquires the lock before appending a number to the list.\n",
        "\n",
        "Removing Function: The remove_numbers function simulates removing numbers from the list. It also sleeps for a random duration, acquires the lock before popping a number from the list, and checks if the list is empty before attempting to remove an item.\n",
        "\n",
        "Threads Creation and Execution: Two threads are created for adding and removing numbers, started, and then the main thread waits for both to finish using join().\n",
        "\n",
        "Output:\n",
        "When you run this program, you'll see the order of numbers added and removed from the list, demonstrating thread-safe operations. The output may vary due to the nature of threading and random sleep durations"
      ],
      "metadata": {
        "id": "pTHLAEIcaCEW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bo7HZuYuaFmW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AN6DqpOnaJ-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5. Describe the methods and tools available in Python for safely sharing data between threads and\n",
        "processes"
      ],
      "metadata": {
        "id": "wYfp4D5OaJvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Python, sharing data safely between threads and processes requires specific methods and tools to prevent race conditions and ensure data integrity. Here’s a rundown of the primary options for both threading and multiprocessing:\n",
        "\n",
        "### Sharing Data Between Threads\n",
        "\n",
        "1. **Threading Locks**:\n",
        "   - **`threading.Lock`**: A basic locking mechanism that prevents multiple threads from accessing shared resources simultaneously. Threads must acquire the lock before accessing the shared resource and release it afterward.\n",
        "   - **Usage**: Ideal for protecting critical sections of code where shared data is modified.\n",
        "\n",
        "2. **RLocks (Reentrant Locks)**:\n",
        "   - **`threading.RLock`**: A lock that can be acquired multiple times by the same thread without causing a deadlock. Useful when a thread needs to call a function that requires the same lock multiple times.\n",
        "\n",
        "3. **Semaphores**:\n",
        "   - **`threading.Semaphore`**: A synchronization primitive that allows a fixed number of threads to access a resource simultaneously. It can be used to limit the number of concurrent accesses to a particular section of code.\n",
        "\n",
        "4. **Condition Variables**:\n",
        "   - **`threading.Condition`**: A mechanism that allows threads to wait for certain conditions to be met before continuing. This is useful for signaling between threads, such as notifying one thread when data is ready.\n",
        "\n",
        "5. **Queues**:\n",
        "   - **`queue.Queue`**: A thread-safe FIFO queue that can be used for communication between threads. It handles locking internally, allowing safe data exchange without explicit locks.\n",
        "   - **Usage**: Ideal for producer-consumer scenarios.\n",
        "\n",
        "### Sharing Data Between Processes\n",
        "\n",
        "1. **Multiprocessing Locks**:\n",
        "   - **`multiprocessing.Lock`**: Similar to `threading.Lock`, it is used to synchronize access to shared resources between processes.\n",
        "\n",
        "2. **Queues**:\n",
        "   - **`multiprocessing.Queue`**: A process-safe FIFO queue that allows communication between processes. It is often used for passing data between producer and consumer processes.\n",
        "\n",
        "3. **Pipes**:\n",
        "   - **`multiprocessing.Pipe`**: A two-way communication channel between processes. It allows sending and receiving data directly between two processes.\n",
        "\n",
        "4. **Shared Memory**:\n",
        "   - **`multiprocessing.Value` and `multiprocessing.Array`**: These allow for sharing simple data types and arrays between processes. They are backed by shared memory, enabling efficient data sharing without copying.\n",
        "   - **`multiprocessing.shared_memory`**: A more advanced shared memory interface introduced in Python 3.8 that allows sharing large data blocks between processes.\n",
        "\n",
        "5. **Managers**:\n",
        "   - **`multiprocessing.Manager`**: Provides a way to create shared objects such as lists, dictionaries, and other complex data structures that can be shared between processes. The Manager handles the synchronization automatically.\n",
        "\n",
        "### Summary\n",
        "\n",
        "In summary, Python offers various tools and methods for safely sharing data between threads and processes:\n",
        "\n",
        "- For threads: Use locks, semaphores, condition variables, and thread-safe queues.\n",
        "- For processes: Use locks, queues, pipes, shared memory, and managers.\n",
        "\n",
        "Choosing the right mechanism depends on the specific requirements of my application, including the nature of the data being shared, the level of concurrency required, and performance considerations."
      ],
      "metadata": {
        "id": "RNk90B7EaXt3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P0XNPITfaZE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "91Up984aaZwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#6. Discuss why it’s crucial to handle exceptions in concurrent programs and the techniques available for\n",
        "doing so."
      ],
      "metadata": {
        "id": "rV5i5NWsaZkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handling exceptions in concurrent programs is crucial for several reasons:\n",
        "\n",
        "### Importance of Exception Handling in Concurrent Programs\n",
        "\n",
        "1. **Program Stability**:\n",
        "   - Concurrent programs often involve multiple threads or processes running simultaneously. An unhandled exception in one thread or process can lead to crashes or unpredictable behavior in the entire application.\n",
        "\n",
        "2. **Data Integrity**:\n",
        "   - Exceptions can occur during critical operations that modify shared data. If these exceptions are not handled properly, the shared state may become inconsistent, leading to further issues down the line.\n",
        "\n",
        "3. **Resource Management**:\n",
        "   - Proper exception handling ensures that resources (like file handles, database connections, or network sockets) are released appropriately, even in the face of errors. This helps prevent resource leaks.\n",
        "\n",
        "4. **Error Propagation**:\n",
        "   - In a concurrent environment, it’s essential to understand where and why errors occur. Without proper handling, exceptions may not propagate back to the main thread, making debugging difficult.\n",
        "\n",
        "5. **User Experience**:\n",
        "   - Graceful handling of exceptions can improve user experience by providing informative error messages or fallbacks, rather than abrupt terminations or undefined behaviors.\n",
        "\n",
        "### Techniques for Handling Exceptions in Concurrent Programs\n",
        "\n",
        "1. **Try-Except Blocks**:\n",
        "   - Using standard try-except blocks within each thread or process allows for localized handling of exceptions. This is the most straightforward method for catching and managing errors in individual tasks.\n",
        "\n",
        "2. **Custom Exception Handling Logic**:\n",
        "   - Implement custom exception classes and handling logic to provide more context about the errors. This can be useful for logging and debugging.\n",
        "\n",
        "3. **Thread and Process Termination**:\n",
        "   - Decide how to handle situations where a thread or process encounters an exception. For example, should it simply log the error and continue, or should it terminate and possibly signal other components?\n",
        "\n",
        "4. **Joining Threads**:\n",
        "   - Use the `join()` method on threads to ensure that the main program waits for threads to complete, which can include catching exceptions raised in those threads.\n",
        "\n",
        "5. **Using Future Objects**:\n",
        "   - In Python's `concurrent.futures` module, you can submit tasks to a thread or process pool and retrieve their results via future objects. If an exception occurs, you can call `future.result()` to get the exception raised in the thread or process, allowing you to handle it gracefully.\n",
        "\n",
        "6. **Threading Events**:\n",
        "   - Use `threading.Event` or similar constructs to signal other threads or the main thread when an exception occurs, allowing for coordinated responses.\n",
        "\n",
        "7. **Error Logging**:\n",
        "   - Implement a centralized logging mechanism to record exceptions and relevant context, which can aid in diagnosing issues without crashing the program.\n",
        "\n",
        "8. **Using a Manager for Shared State**:\n",
        "   - When using `multiprocessing.Manager`, exceptions can be communicated back to the main program or other processes by returning error codes or messages from managed objects.\n",
        "\n",
        "### Example of Exception Handling with Threads\n",
        "\n",
        "Here’s a simple example of handling exceptions in a multithreaded environment using Python:\n",
        "\n",
        "```python\n",
        "import threading\n",
        "import time\n",
        "\n",
        "def worker(n):\n",
        "    try:\n",
        "        if n == 5:\n",
        "            raise ValueError(\"An error occurred in thread\")\n",
        "        print(f\"Thread {n} is working.\")\n",
        "        time.sleep(1)\n",
        "    except Exception as e:\n",
        "        print(f\"Thread {n} caught an exception: {e}\")\n",
        "\n",
        "threads = []\n",
        "for i in range(10):\n",
        "    thread = threading.Thread(target=worker, args=(i,))\n",
        "    threads.append(thread)\n",
        "    thread.start()\n",
        "\n",
        "for thread in threads:\n",
        "    thread.join()\n",
        "\n",
        "print(\"All threads have completed.\")\n",
        "```\n",
        "\n",
        "### Conclusion\n",
        "\n",
        "Handling exceptions in concurrent programs is essential for maintaining stability, ensuring data integrity, managing resources effectively, and improving user experience. Employing various techniques like try-except blocks, future objects, and centralized logging can significantly enhance the robustness of concurrent applications."
      ],
      "metadata": {
        "id": "tpvJiipHa3bG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P6uKcqWMa5KC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zRF1Xf8Ua5mV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#7. Create a program that uses a thread pool to calculate the factorial of numbers from 1 to 10 concurrently.\n",
        "Use concurrent.futures.ThreadPoolExecutor to manage the threads"
      ],
      "metadata": {
        "id": "1VdPovXqa5aJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's a Python program that uses `concurrent.futures.ThreadPoolExecutor` to calculate the factorial of numbers from 1 to 10 concurrently. The program defines a function to compute the factorial and submits tasks to the thread pool for execution.\n",
        "\n",
        "```python\n",
        "import concurrent.futures\n",
        "import math\n",
        "\n",
        "# Function to calculate the factorial\n",
        "def calculate_factorial(n):\n",
        "    return math.factorial(n)\n",
        "\n",
        "# Main function to manage the thread pool and calculate factorials\n",
        "def main():\n",
        "    # Create a thread pool executor\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        # Submit tasks to calculate factorial for numbers 1 to 10\n",
        "        futures = {executor.submit(calculate_factorial, i): i for i in range(1, 11)}\n",
        "\n",
        "        # Retrieve and print results\n",
        "        for future in concurrent.futures.as_completed(futures):\n",
        "            number = futures[future]\n",
        "            try:\n",
        "                result = future.result()  # Get the result of the calculation\n",
        "                print(f\"Factorial of {number} is {result}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error calculating factorial of {number}: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "```\n",
        "\n",
        "### Explanation:\n",
        "\n",
        "1. **Function Definition**:\n",
        "   - The `calculate_factorial` function uses the `math.factorial` function to compute the factorial of a given number.\n",
        "\n",
        "2. **Thread Pool Executor**:\n",
        "   - The `ThreadPoolExecutor` is created using a context manager (`with` statement) to ensure proper cleanup after tasks are complete.\n",
        "\n",
        "3. **Task Submission**:\n",
        "   - A dictionary comprehension is used to submit tasks to the thread pool for numbers 1 through 10. Each task is submitted with `executor.submit(calculate_factorial, i)`, which schedules the factorial calculation.\n",
        "\n",
        "4. **Result Retrieval**:\n",
        "   - The program uses `concurrent.futures.as_completed()` to retrieve results as they become available. This is useful for processing results in the order of completion rather than submission.\n",
        "\n",
        "5. **Error Handling**:\n",
        "   - The code handles any exceptions that may occur during the execution of tasks, printing an appropriate message if an error arises.\n",
        "\n",
        "### Output\n",
        "\n",
        "When i run this program, i should see output similar to this (the order may vary due to the nature of threading):\n",
        "\n",
        "```\n",
        "Factorial of 1 is 1\n",
        "Factorial of 2 is 2\n",
        "Factorial of 3 is 6\n",
        "Factorial of 4 is 24\n",
        "Factorial of 5 is 120\n",
        "Factorial of 6 is 720\n",
        "Factorial of 7 is 5040\n",
        "Factorial of 8 is 40320\n",
        "Factorial of 9 is 362880\n",
        "Factorial of 10 is 3628800\n",
        "```\n",
        "\n",
        "This program effectively demonstrates the use of a thread pool to perform concurrent calculations in Python."
      ],
      "metadata": {
        "id": "QlF9uFBlbkAF"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k0ypDP29bohC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dTAsXjh5bpYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#8. Create a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in\n",
        "parallel. Measure the time taken to perform this computation using a pool of different sizes (e.g., 2, 4, 8\n",
        "processes)."
      ],
      "metadata": {
        "id": "UeSYB7QXbwz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here’s a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in parallel. The program measures the time taken to perform this computation with different pool sizes (2, 4, and 8 processes)"
      ],
      "metadata": {
        "id": "5zl2GgFdby5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "import time\n",
        "\n",
        "# Function to compute the square of a number\n",
        "def compute_square(n):\n",
        "    return n * n\n",
        "\n",
        "# Function to perform the computation using a pool of processes\n",
        "def compute_with_pool(pool_size):\n",
        "    with multiprocessing.Pool(processes=pool_size) as pool:\n",
        "        results = pool.map(compute_square, range(1, 11))\n",
        "    return results\n",
        "\n",
        "def main():\n",
        "    pool_sizes = [2, 4, 8]\n",
        "    for size in pool_sizes:\n",
        "        start_time = time.time()  # Start timing\n",
        "        results = compute_with_pool(size)\n",
        "        end_time = time.time()  # End timing\n",
        "        print(f\"Pool size: {size}, Results: {results}, Time taken: {end_time - start_time:.4f} seconds\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ODVL0ZVceAc",
        "outputId": "c96e8bd4-9bc1-45fa-f31f-f314597cb2bb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pool size: 2, Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100], Time taken: 0.0612 seconds\n",
            "Pool size: 4, Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100], Time taken: 0.0713 seconds\n",
            "Pool size: 8, Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100], Time taken: 0.1655 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s9jzZ-PKcgQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:**\n",
        "\n",
        "**Function Definition:**\n",
        "\n",
        "*    compute_square(n): A simple function that returns the square of the number n.\n",
        "\n",
        "**Compute with Pool**:\n",
        "\n",
        "*  compute_with_pool(pool_size): This function creates a multiprocessing.Pool with the specified number of processes. It then uses pool.map() to apply compute_square to the numbers from 1 to 10 in parallel.\n",
        "\n",
        "**Main Function:**\n",
        "\n",
        "*  The main() function defines a list of pool sizes (2, 4, and 8) and iterates over each size. It measures the time taken to perform the computations using time.time() to record the start and end times.\n",
        "\n",
        "**Output:**\n",
        "\n",
        "The program prints the pool size, the results of the computations, and the time taken for each pool size"
      ],
      "metadata": {
        "id": "A6FU4WHdcqFW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Pool size: 2, Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100], Time taken: 0.0030 seconds\n",
        "Pool size: 4, Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100], Time taken: 0.0025 seconds\n",
        "Pool size: 8, Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100], Time taken: 0.0021 seconds\n"
      ],
      "metadata": {
        "id": "VT4B-VoHdKAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note:\n",
        "The actual time taken may vary based on the system's performance and current load. This program effectively demonstrates how to use multiprocessing.Pool for parallel computations and how the pool size can impact performance"
      ],
      "metadata": {
        "id": "VRdVDBPJdUYP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ItBMfmZEdYxg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}